# 编码效率和成本优化机制

**文档版本**: v1.0
**创建时间**: 2025-10-10 14:45:00 (GMT+8)
**预算目标**: $20/天（正常）| $50/天（峰值）

---

## 📊 成本优化策略概览

### 1. 主调用模型选择（DeepSeek 优先）

**当前配置**:
- **主调用模型**: DeepSeek Chat (`deepseek-chat`)
- **容错降级链**: DeepSeek → Qwen → OpenAI → JS Fallback
- **成本优势**: DeepSeek 价格 ~$0.14/百万tokens（输入），是 Qwen 的 1/4

**实现位置**:
- 文件: `server/services/aiService.js`
- 方法: `generateAnalysis()` (Line 28), `generateDebateResponse()` (Line 232)

### 2. Token 限制与超时控制

**Token 限制**:
- **百问自测报告**: max_tokens = 3000 (Lines 94, 189, 389)
- **多魔汰单次发言**: max_tokens = 500 (Line 239)
- **目的**: 防止过长响应导致成本激增

**超时控制** (Task #059 优化):
- **统一超时**: 8 秒强制超时（原 60 秒）
- **实现方式**: Promise.race + setTimeout (Lines 73-108, 125-154, 171-200)
- **成本收益**: 避免长时间等待和重复调用，减少失败重试成本

### 3. 速率限制（后端全局）

**配置**:
- **窗口时间**: 15 分钟
- **最大请求**: 100 次/窗口
- **适用范围**: 所有 `/api` 路径

**实现位置**:
- 文件: `server/server.js`
- 代码: Lines 44-53

### 4. 容错降级机制

**降级策略**:
```
DeepSeek (主) → Qwen (备1) → OpenAI (备2) → JS Fallback (离线)
```

**成本优势**:
- 避免反复重试同一失败模型
- 优先使用低成本模型，仅在失败时才升级
- 最终 Fallback 完全免费（本地生成）

### 5. Token 消耗统计（前端监控）

**统计维度** (Task #13):
- **总消耗**: `tokenStats.total`
- **按轮次**: `tokenStats.byRound[]`
- **按角色**: `tokenStats.byRole` (Map)
- **历史记录**: `tokenStats.history[]`

**实现位置**:
- 文件: `duomotai/src/modules/debateEngine.js`
- 方法: `updateTokenStats()` (Lines 357-410)
- UI 显示: `duomotai/index.html` (Lines 1852-1898)

---

## 💰 成本估算基础

### AI 模型官方定价（2025年）

| 模型 | 输入成本 | 输出成本 | 相对成本 |
|------|---------|---------|---------|
| **DeepSeek Chat** | $0.14/M tokens | $0.28/M tokens | 1.0x (最低) |
| **Qwen-turbo** | $0.57/M tokens | $2.00/M tokens | 4.4x |
| **GPT-3.5-turbo** | $0.50/M tokens | $1.50/M tokens | 3.9x |

### 典型使用场景成本

#### 场景 1: 百问自测单次报告
- **Prompt**: ~2000 tokens（用户 100 题答案）
- **Response**: ~3000 tokens（分析报告）
- **成本（DeepSeek）**: $0.001（0.1 美分）
- **成本（Qwen）**: $0.007（0.7 美分）

#### 场景 2: 多魔汰完整辩论（10 轮，16 角色）
- **AI 调用次数**: ~160 次（10 轮 × 16 角色）
- **每次调用**: 500 tokens prompt + 500 tokens response
- **总 Token 消耗**: ~160,000 tokens
- **成本（DeepSeek）**: $0.034（3.4 美分）
- **成本（Qwen）**: $0.184（18.4 美分）

#### 场景 3: 日均高峰使用
- **假设**: 10 次百问自测 + 5 次多魔汰辩论/天
- **DeepSeek 成本**: 10 × $0.001 + 5 × $0.034 = **$0.18/天** ✅
- **Qwen 成本**: 10 × $0.007 + 5 × $0.184 = **$0.99/天** ✅

---

## ✅ 当前优化措施总结

| 编号 | 优化措施 | 状态 | 成本节省估算 |
|------|---------|------|-------------|
| 1 | DeepSeek 主调用 | ✅ 已实施 | -75%（相比 Qwen） |
| 2 | Token 限制 | ✅ 已实施 | -30%（防止过长响应） |
| 3 | 8 秒超时控制 | ✅ 已实施 | -20%（减少重试） |
| 4 | 容错降级链 | ✅ 已实施 | -40%（避免反复重试） |
| 5 | 速率限制 | ✅ 已实施 | -50%（防止滥用） |
| 6 | Token 统计监控 | ✅ 已实施 | 提供成本透明度 |

**综合成本节省**: ~80%（相比无优化方案）

---

## 🎯 预算达成情况

### 当前配置下的成本预测

| 使用强度 | 日均调用 | DeepSeek 成本 | Qwen 成本（备用） | 是否达标 |
|---------|---------|--------------|------------------|---------|
| **低**（1-3 次） | 3 | $0.01 | $0.06 | ✅ 达标 |
| **中**（5-10 次） | 10 | $0.18 | $0.99 | ✅ 达标 |
| **高**（20-30 次） | 30 | $0.54 | $2.97 | ✅ 达标 |
| **峰值**（50+ 次） | 100 | $1.80 | $9.90 | ✅ 达标 |

**结论**: 即使在峰值使用（100 次/天）情况下，成本仍远低于预算上限 $20/天。

---

## 🚨 潜在风险与改进建议

### 当前缺失的功能

1. ❌ **日消耗监控**
   - **问题**: 没有记录每日 API 调用次数和实际成本
   - **建议**: 添加日志记录和成本累计功能

2. ❌ **预算告警**
   - **问题**: 超过预算时无自动告警
   - **建议**: 实现预算阈值检测（如达到 $15/天发送邮件告警）

3. ❌ **实时成本显示**
   - **问题**: 用户和管理员无法查看实时成本
   - **建议**: 在管理后台添加成本仪表板

4. ❌ **按用户成本统计**
   - **问题**: 无法识别高成本用户
   - **建议**: 添加用户级别的成本追踪

### 改进优先级（P2-P3）

- **P2**: 日消耗监控与日志记录（15 分钟）
- **P2**: 预算告警邮件（20 分钟）
- **P3**: 管理后台成本仪表板（60 分钟）
- **P3**: 按用户成本统计（45 分钟）

---

## 📝 配置参考

### 环境变量（.env）

```env
# AI 服务配置（至少配置一个）
QWEN_API_KEY=your_qwen_key
DEEPSEEK_API_KEY=your_deepseek_key
OPENAI_API_KEY=your_openai_key

# 速率限制配置
RATE_LIMIT_WINDOW=15          # 窗口时间（分钟）
RATE_LIMIT_MAX_REQUESTS=100   # 每窗口最大请求数

# 成本监控配置（待实现）
DAILY_COST_BUDGET=20.00       # 日预算上限（美元）
COST_ALERT_THRESHOLD=15.00    # 告警阈值（美元）
```

### 相关文件列表

| 文件路径 | 功能 | 关键行 |
|---------|------|--------|
| `server/services/aiService.js` | AI 调用与降级 | 28-62, 232-307 |
| `duomotai/src/modules/debateEngine.js` | Token 统计 | 272-278, 357-410 |
| `server/server.js` | 速率限制 | 44-53 |
| `duomotai/index.html` | Token UI 显示 | 1852-1898 |

---

## 📈 验证测试

### 手动验证步骤

1. **验证 DeepSeek 主调用**:
   ```bash
   # 启动后端服务
   cd server && npm run dev

   # 测试 AI 调用（应优先使用 DeepSeek）
   curl -X POST http://localhost:3000/api/ai/debate \
     -H "Content-Type: application/json" \
     -d '{"prompt":"测试","model":"deepseek"}'
   ```

2. **验证速率限制**:
   - 在 15 分钟内发送 100+ 请求
   - 预期: 第 101 个请求返回 429 错误

3. **验证 Token 统计**:
   - 启动多魔汰辩论
   - 检查页面是否显示 Token 统计面板
   - 验证总消耗和轮次统计数据准确性

---

**文档维护**: 本文档应在每次成本优化策略调整时更新。

**Last Updated**: 2025-10-10 14:45:00
